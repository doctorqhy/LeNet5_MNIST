import tensorflow as tf


image_size = 28
num_channels = 1
num_labels = 10

#定义第一层参数
#第一层过滤器大小
conv1_size = 5
#第一层过滤器个数
conv1_deep = 32

#定义第二层参数
#第二层过滤器大小
conv2_size = 5
#第二层过滤器个数
conv2_deep = 64

#定义全连接层节点个数
fc_size = 512


def inference(input_tensor,train,regularizer):

    with tf.variable_scope('layer1-conv1'):

        #第一层卷积层权重
        conv1_weights = tf.get_variable('weight',[conv1_size,conv1_size,num_channels,conv1_deep],initializer=tf.truncated_normal_initializer(stddev=0.1))
        #第一层卷积层偏置项
        conv1_biases = tf.get_variable('biases',[conv1_deep],initializer=tf.constant_initializer(0.0))
        #第一层卷积
        conv1 = tf.nn.conv2d(input_tensor,conv1_weights,[1,1,1,1],padding='SAME')
        #激活
        relu1 = tf.nn.relu(tf.nn.bias_add(conv1,conv1_biases))

    with tf.variable_scope('layer2-pool1'):

        #第一层池化层
        pool1 = tf.nn.max_pool(relu1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

    with tf.variable_scope('layer3-conv2'):

        #第二层卷积层权重
        conv2_weights = tf.get_variable('weights',[conv2_size,conv2_size,conv1_deep,conv2_deep],initializer=tf.truncated_normal_initializer(stddev=0.1))
        #第二层卷积层偏置项
        conv2_biases = tf.get_variable('biases',[conv2_deep],initializer=tf.constant_initializer(0.0))
        #第二层卷积
        conv2  = tf.nn.conv2d(pool1,conv2_weights,[1,1,1,1],padding='SAME')
        #激活
        relu2 = tf.nn.relu(tf.nn.bias_add(conv2,conv2_biases))


    with tf.variable_scope('layer4-pool2'):

        #第二层池化层
        pool2 = tf.nn.max_pool(relu2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

    #将最后一层池化层转化为全连接层的输入格式
    #得到池化层输出矩阵的维度，一共四维，第一维是一个batch大小，第二维矩阵长度，第三维矩阵宽度，第四维矩阵深度
    pool_shape = pool2.get_shape().as_list()
    node = pool_shape[1] * pool_shape[2] * pool_shape[3]
    #转化好的全连接层的输入，batch行，node列
    reshaped = tf.reshape(pool2,[pool_shape[0],node])

    with tf.variable_scope('layer5-fc1'):

        fc1_weights = tf.get_variable('weights',[node,fc_size],initializer=tf.truncated_normal_initializer(stddev=0.1))
        if regularizer != None:
            tf.add_to_collection('losses',regularizer(fc1_weights))
        fc1_biases = tf.get_variable('biases',[fc_size],initializer=tf.constant_initializer(0.1))

        fc1 = tf.nn.relu(tf.matmul(reshaped,fc1_weights) + fc1_biases)
        if train:
            fc1 = tf.nn.dropout(fc1,0.5)

    with tf.variable_scope('layer6-fc2'):

        fc2_weights = tf.get_variable('weights',[fc_size,num_labels],initializer=tf.truncated_normal_initializer(stddev=0.1))

        if regularizer != None:
            tf.add_to_collection('losses',regularizer(fc2_weights))
        fc2_biases = tf.get_variable('biases',[num_labels],initializer=tf.constant_initializer(0.1))

        fc2 = tf.matmul(fc1,fc2_weights) + fc2_biases

    return fc2
